{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_target = iris.target\n",
    "\n",
    "train, test, train_labels, test_labels = train_test_split(iris_data, iris_target, test_size = 0.2)\n",
    "\n",
    "\n",
    "# a = train[train_labels == 0][:,:2]\n",
    "# a_labels = train_labels[train_labels == 0]\n",
    "# b = train[train_labels == 1][:,:2]\n",
    "# b_labels = train_labels[train_labels == 1]\n",
    "\n",
    "# train = np.concatenate((a, b))\n",
    "# labels = np.concatenate((a_labels, b_labels))\n",
    "\n",
    "# shuffle_index = np.random.permutation(79)\n",
    "# Train, Train_labels = train[shuffle_index], labels[shuffle_index]\n",
    "\n",
    "# plt.scatter(Train[Train_labels == 1][:,1], Train[Train_labels == 1][:,2])\n",
    "# plt.scatter(Train[Train_labels == 0][:,1], Train[Train_labels == 0][:,2])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from  sklearn import datasets\n",
    "# nist = datasets.load_digits()\n",
    "# train, test, train_labels, test_labels = train_test_split(np.float32(nist.data), nist.target, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many iterations need to train: 100\n",
      "Number of wrong classsified examples:  0\n",
      "Score:  100.0 %\n",
      "---------------------------------------------------------\n",
      "(array([-14.82340419,  -6.85414502,  18.87390113,  22.50100397]), -14.573626350553646)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "def sign(x):\n",
    "    '''\n",
    "    Function that return 1 if value is grater than 0\n",
    "    and -1 in other case.\n",
    "    param: x: value\n",
    "    return: -1, 1\n",
    "    '''\n",
    "    if x >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def prepare_data(class_to_clf):\n",
    "    '''\n",
    "    Function that prepere data to classification.\n",
    "    param number: number to classify.\n",
    "    return: labels of training and test data.\n",
    "    '''\n",
    "    if class_to_clf not in np.unique(train_labels):\n",
    "        raise ValueError('Class not found')\n",
    "    y = np.ones_like(train_labels)\n",
    "    y[train_labels == class_to_clf] = 1\n",
    "    y[train_labels != class_to_clf] = -1\n",
    "    \n",
    "    y_test = np.ones_like(test_labels)\n",
    "    y_test[test_labels == class_to_clf] = 1\n",
    "    y_test[test_labels != class_to_clf] = -1\n",
    "    \n",
    "    return y, y_test\n",
    "\n",
    "\n",
    "class my_Percepron(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Class that represent single perceptron.\n",
    "    '''\n",
    "    def __init__(self, lr = 0.1):\n",
    "        '''\n",
    "        param: lr: learning rate.\n",
    "        '''\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, train, target):\n",
    "        '''\n",
    "        Function that train data - search for best weights and bias.\n",
    "        param: train: training data.\n",
    "        param: target: labels of training data.\n",
    "        '''\n",
    "        self.W = np.random.rand(len(train[0])+1)         # Initialization random weights.\n",
    "        X = np.hstack((np.ones((len(train), 1)), train)) # Initialization bias as index 0 of training data.\n",
    "        misclasified = True\n",
    "        iterations = 0\n",
    "        while misclasified and iterations < 100:\n",
    "            iterations +=1\n",
    "            misclasified = False\n",
    "            for xi, yi in zip(X, target):   \n",
    "                value = sign(xi.dot(self.W))             # Dot product of X[i] and weights, closed in sign function, \n",
    "                error = yi - value                       # Error = desired - our_value, possible cases: 1 - 1 = 0,\n",
    "                if error != 0:\n",
    "                    misclasified = True\n",
    "                self.W += self.lr*error*xi               # 1 - (-1) = 2, -1 - 1 = -2, -1 - (-1) = 0\n",
    "                \n",
    "        return iterations\n",
    "                    \n",
    "    def predict(self, data):\n",
    "        '''\n",
    "        Function that predicts value of data.\n",
    "        param: data: data to predict.\n",
    "        return: weighted sum of data.\n",
    "        '''\n",
    "        data = np.insert(data, 0, 1)\n",
    "        value = data.dot(self.W)\n",
    "        return np.array(value)\n",
    "    \n",
    "    def score(self, test, labels):\n",
    "        '''\n",
    "        Function that return score of prediction.\n",
    "        param: test: test data.\n",
    "        param: labels: labels of test data.\n",
    "        return score of prediction.\n",
    "        '''\n",
    "        predicted = []\n",
    "        for i in test:\n",
    "            predicted.append(sign(self.predict(i)))\n",
    "#         print('Weights:', self.W[1:])\n",
    "#         print('Bias: ', self.W[0])\n",
    "        print('Number of wrong classsified examples: ', np.sum(predicted != labels))\n",
    "        return np.sum(predicted == labels) / len(predicted)\n",
    "    \n",
    "    def return_W_B(self):\n",
    "        '''\n",
    "        Function that return weights and bias.\n",
    "        '''\n",
    "        return self.W[1:], self.W[0]\n",
    "    \n",
    "bp = my_Percepron()\n",
    "number = 2\n",
    "y, y_test = prepare_data(number)\n",
    "print('How many iterations need to train:', bp.fit(train, y))\n",
    "print('Score: ', bp.score(test, y_test)*100, '%')\n",
    "print('---------------------------------------------------------')\n",
    "print(bp.return_W_B())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wrong classsified examples:  0\n",
      "Number of wrong classsified examples:  0\n",
      "Number of wrong classsified examples:  0\n",
      "Number of wrong classsified examples:  0\n",
      "Number of wrong classsified examples:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(bp, test, y_test, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OVAClf(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Class that represent 10 binary Perceptrons that recognizes hand written digits.\n",
    "    '''\n",
    "    def fit(self, train, labels):\n",
    "        '''\n",
    "        Function that train 10 single perceptron for every number.\n",
    "        param: train: training data.\n",
    "        param: labels: labels of training data\n",
    "        '''\n",
    "        self.perceptrons = [my_Percepron() for i in range(len(np.unique(labels)))]\n",
    "        for index, perceptron in enumerate(self.perceptrons):\n",
    "            y, y_test = prepare_data(index)\n",
    "            perceptron.fit(train, y)\n",
    "            \n",
    "    def predict(self, number):\n",
    "        '''\n",
    "        Function that predict label of data.\n",
    "        param: number: data to predict.\n",
    "        return: Array with propability of every number.\n",
    "        '''\n",
    "        propab = []\n",
    "        for perceptron in self.perceptrons:\n",
    "            guess_ = perceptron.predict(number)\n",
    "            propab.append(guess_)\n",
    "        propab = np.argmax(np.array(propab))\n",
    "        return propab\n",
    "    \n",
    "    def score(self, data, labels):\n",
    "        '''\n",
    "        Function that calculate score of good classified examples.\n",
    "        param: data: data to classify.\n",
    "        param: labels of data.\n",
    "        return: score of good classified examples.\n",
    "        '''\n",
    "        propab = []\n",
    "        for i in range(len(data)):\n",
    "            propab.append([])\n",
    "            for perceptron in self.perceptrons:\n",
    "                guess_ = perceptron.predict(data[i])\n",
    "                propab[i].append(guess_)\n",
    "            propab[i] = np.argmax(np.array(propab[i]))\n",
    "        print('Number of wrong classsified examples: ', np.sum(propab != labels))\n",
    "        return np.sum(propab == labels) / len(labels)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wrong classsified examples:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovaclf = OVAClf()\n",
    "ovaclf.fit(train, train_labels)\n",
    "ovaclf.score(test,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wrong classsified examples:  6\n",
      "Number of wrong classsified examples:  5\n",
      "Number of wrong classsified examples:  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.4,  0.5,  0.5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(ovaclf, test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
