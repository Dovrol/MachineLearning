{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_with_bias = np.c_[np.ones([len(X), 1]), X]\n",
    "train, test, y_train, y_test = train_test_split(X_with_bias, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y):\n",
    "    cols = y.max()+1\n",
    "    rows = len(y)\n",
    "    new = np.zeros((rows, cols))\n",
    "    new[np.arange(rows), y] = 1 #wow\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k = \\dfrac{\\exp\\left(s_k(\\mathbf{x})\\right)}{\\sum\\limits_{j=1}^{K}{\\exp\\left(s_j(\\mathbf{x})\\right)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    exps = np.exp(logits)\n",
    "    exp_sums = np.sum(exps, axis=1, keepdims=True)\n",
    "    return exps / exp_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with bias as index 0:\n",
      "[[ 1.   5.   3.5  1.6  0.6]\n",
      " [ 1.   7.7  2.6  6.9  2.3]\n",
      " [ 1.   6.3  2.5  4.9  1.5]\n",
      " [ 1.   5.8  2.7  4.1  1. ]\n",
      " [ 1.   6.4  2.7  5.3  1.9]]\n",
      "Labels:\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print('Data with bias as index 0:')\n",
    "print(train[:5])\n",
    "print('Labels:')\n",
    "print(to_one_hot(y_train[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_reg():\n",
    "    def __init__(self, lr = 0.01, eps = 1e-7, iterations = 5001):\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.iterations = iterations\n",
    "        \n",
    "    def fit(self, train, y):\n",
    "        self.theta = np.random.randn(train.shape[1], len(np.unique(y)))\n",
    "        one_hot_y = to_one_hot(y)\n",
    "        m = len(train)\n",
    "        for i in range(self.iterations):\n",
    "            Y_proba = softmax(train.dot(self.theta))\n",
    "            loss = -np.mean(np.sum(one_hot_y*np.log(Y_proba+ self.eps)))\n",
    "            if i %5000 == 0:\n",
    "                print(i, loss)\n",
    "            error = Y_proba - one_hot_y\n",
    "            gradients = 1/m * train.T.dot(error)\n",
    "            self.theta -= self.lr * gradients\n",
    "            \n",
    "    def predict(self, data):\n",
    "        data = np.array(data)\n",
    "        return [np.argmax(i) for i in softmax(data.dot(self.theta)).reshape(len(data),3)]\n",
    "    \n",
    "    def score(self, data, labels):\n",
    "        data = np.array(data)\n",
    "        score = np.sum(self.predict(data) == labels) / len(data)\n",
    "        return score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "softi = Softmax_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 847.262788193\n",
      "5000 23.8131370003\n"
     ]
    }
   ],
   "source": [
    "softi.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94999999999999996"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softi.score(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
