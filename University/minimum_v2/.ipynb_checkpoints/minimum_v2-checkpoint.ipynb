{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podstawy Sztucznej Inteligencji 2018/2019\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prosze uzupelnic kod tam gdzie znajduje napis `YOUR CODE HERE` lub 'YOUR ANSWER HERE'.\n",
    "\n",
    "Warto zresetowac 'kernel' i sprawdzic czy caly notatnik uruchamiany od poczatku nie daje bledow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4de006657682e1a61ac738dc77d5d0be",
     "grade": false,
     "grade_id": "cell-9c1b9ab4d37b3676",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Numeryczne szukanie minimum funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "60a40fdd706d24305ff98cfe41b599a4",
     "grade": false,
     "grade_id": "cell-2ee70ea63f3a125e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a970e17eb24534d3d254b467ed0fe9db",
     "grade": false,
     "grade_id": "cell-220464f9c62a6f30",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Jest to najprostsza metoda szukania minimum funkcji $f(x)$. Argumentem funkcji w ogólności może być wektor $\\overline{x}$ lub w najprostszym przypadku (rozpatrywanym teraz) liczba. Jest to metoda iteracyjna, zaczyna od pewnego punktu w przestrzeni parametrów i w każdym kroku przesuwa ten punkt w stronę wskazywaną przez gradient funkcji.\n",
    "\n",
    "$$x_{i+1} =x_{i}-\\alpha \\frac{\\partial f}{\\partial x}(x_i)  $$\n",
    "\n",
    "Znak minus bierze się stąd, że gradient wskazuje kierunek najszybszego rośnięcia funkcji, a chcemy szukać minimum. Parametr $\\alpha$ to długość kroku, należy go dobrać odpowiednio do zagadnienia. Zbyt mała wartość może spowodować, że metoda będzie działać powoli lub utknie w minimum lokalnym, zbyt duża wartość spowoduje, że program nigdy nie znajdzie dokładnej odpowiedzi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "78c86f9aa20b20ad694a0d56343adc8a",
     "grade": false,
     "grade_id": "cell-19b3fb5a8397f8a6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**1\\. Funkcja kwadratowa**\n",
    "\n",
    "Jedną z najprostszych funkcji, na których można ćwiczyć to funkcja kwadratowa $f(x)=ax^2+bx+c$.\n",
    "\n",
    "Jej gradient wynosi $\\frac{\\partial f}{\\partial x}=2ax+b$\n",
    "\n",
    "Zbierając to razem dostajemy następujący wzór (nie pomylić alfy z a):\n",
    "\n",
    "$$x_{i+1} =x_{i}-\\alpha (2ax_i+b)  $$\n",
    "\n",
    "Jako punkt początkowy $x_0$ należy wybrać losowo liczbę z przedziału [-10,10], parametr \"steps\" to ilość kroków optymalizacji, które ma wykonać program. Jako długość kroku $\\alpha$ można wziąć na początek 0.01.\n",
    "\n",
    "Funkcja SGD1 powinna zwrócić wartość x dla którego $f(x)$ ma minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "abc47493e4ec0a33a1c2e2573908b838",
     "grade": false,
     "grade_id": "cell-431e25a74edef45d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def SGD1(a, b, c, steps):\n",
    "    alpha - 0.1\n",
    "    for i in steps:\n",
    "        x -= - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "59ae9deb39835682f17d7d2534120332",
     "grade": true,
     "grade_id": "cell-b23fb30d26f8ff4b",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(SGD1(2, -3, 1, 10000), 0.75)\n",
    "np.testing.assert_almost_equal(SGD1(2, 2, 1.23, 10000), -0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ce5b528c636b2bc0c1bdfdeea7a4aa8a",
     "grade": false,
     "grade_id": "cell-42cbed9eb30c75b8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**2\\. Regresja liniowa**\n",
    "\n",
    "Regresja liniowa to metoda znajdowania parametrów prostej $y=ax+b$ która najlepiej opisuje dane. Najczęściej robi się to [metodą najmniejszych kwadratów](https://pl.wikipedia.org/wiki/Metoda_najmniejszych_kwadrat%C3%B3w), która polega na zminimalizowaniu następującej funkcji:\n",
    "\n",
    "$$L(a,b)=\\sum_{j=0}^{n-1} (y_j-ax_j-b)^2$$\n",
    "\n",
    "gdzie $x_i,y_i$ to odpowiednia para danych do których dopasowujemy prostą.\n",
    "\n",
    "Gradient L ze względu na a i b jest równy:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial a}=-2\\sum_{j=0}^{n-1}(y_j-ax_j-b)x_j$$\n",
    "$$\\frac{\\partial L}{\\partial b}=-2\\sum_{j=0}^{n-1}(y_j-ax_j-b)$$\n",
    "\n",
    "Tym razem równania wyglądają następująco\n",
    "$$a_{i+1}=a_i-\\alpha\\frac{\\partial L}{\\partial a}=a_i+2\\alpha\\sum_{j=0}^{n-1}(y_j-ax_j-b)x_j$$\n",
    "$$b_{i+1}=b_i-\\alpha\\frac{\\partial L}{\\partial b}=b_i+2\\alpha\\sum_{j=0}^{n-1}(y_j-ax_j-b)$$\n",
    "\n",
    "\n",
    "Funksja SGD_reglin powinna zwrócić np.array z wartościami znalezionych a i b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "28beb6d7e31fb854591f86e83c462af2",
     "grade": false,
     "grade_id": "cell-3cbf264c883c8209",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Generowanie danych do regresji liniowej\n",
    "def genData(n, a, b, useNoise):\n",
    "    result = np.zeros((n, 2)) #x_i=result[i][0], y_i=result[i][1]\n",
    "    for i in range(0, n):\n",
    "        x = -10 + 20 * np.random.uniform()\n",
    "        result[i][0] = x\n",
    "        result[i][1] = a * x + b\n",
    "        if useNoise == True:\n",
    "            result[i][1] += 0.1 * np.random.normal()\n",
    "    return result\n",
    "\n",
    "data_reglin1 = genData(100, 2, -3, False)\n",
    "data_reglin2 = genData(100, 0.123, 1.4142, True)\n",
    "\n",
    "answer_reglin1 = np.polyfit(data_reglin1[:,0], data_reglin1[:,1],1)\n",
    "answer_reglin2 = np.polyfit(data_reglin2[:,0], data_reglin2[:,1],1)\n",
    "print(answer_reglin1)\n",
    "print(answer_reglin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a8039ebe0baf20f0a4ff59e2dec86548",
     "grade": false,
     "grade_id": "cell-760e13648dbd2375",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def SGD_reglin(data, alfa, steps):\n",
    "    a = 0.0\n",
    "    b = 0.0\n",
    "    x = data[:,0]\n",
    "    y = data[:,1]\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "print(SGD_reglin(data_reglin1, 0.0001, 10000))\n",
    "print(SGD_reglin(data_reglin2, 0.0001, 10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6e991944c2d2c58cdfe32c381937eab0",
     "grade": true,
     "grade_id": "cell-d2c7ea1e71132f51",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "answer_reglin1=np.polyfit(data_reglin1[:,0],data_reglin1[:,1],1)\n",
    "answer_reglin2=np.polyfit(data_reglin2[:,0],data_reglin2[:,1],1)\n",
    "np.testing.assert_almost_equal(SGD_reglin(data_reglin1,0.0001,10000),np.array(answer_reglin1))\n",
    "np.testing.assert_almost_equal(SGD_reglin(data_reglin2,0.0001,10000),np.array(answer_reglin2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d9ed1bd6e08dd8989d84dc7b5e93728f",
     "grade": false,
     "grade_id": "cell-bec11e8c99c8b2cd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**3\\. Funkcja Rosenbrocka**\n",
    "\n",
    "Zadanie polega na znalezieniu minimum następującej funkcji $f(x,y)=(a-x)^2+b(y-x^2)^2$.\n",
    "\n",
    "\n",
    "Funkcja SGD_rosenbrok powinna zwrócić np.array z wartościami znalezionych x i y. Zacznij od losowo wybranych $x_0, y_0 \\in [-a,a]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3340ebc18e8ac0236fe8dde842c1b393",
     "grade": false,
     "grade_id": "cell-6d4a8f8ccb281064",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def SGD_rosenbrock(a, b, alfa, steps):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "588138bbb534fa535a641c440487c0b5",
     "grade": true,
     "grade_id": "cell-859cdf5fda9c3009",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(SGD_rosenbrock(-1, 100, 0.001, 1000000),np.array((-1, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6b2438bfe1d355b6bd1f0f291325b2dc",
     "grade": false,
     "grade_id": "cell-019be2511a0956f1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**4\\. Fitowanie wielomianu**\n",
    "\n",
    "Tym razem należy dopasować wielomian p(x) stopnia $N$.\n",
    "\n",
    "$$L(\\overline{a})=\\sum_{i=0}^{n-1} (y_i-p(x_i))^2$$\n",
    "$$p(x)=\\sum_{j=0}^{N} a_j x^j$$\n",
    "\n",
    "Gradient L ze względu na $a_j$ jest równy:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial a_j}=-2\\sum_{i=0}^{n-1}(y_i-p(x_i))x_i^j$$\n",
    "\n",
    "\n",
    "Funkcja SGD_polyfit powinna zwrócić np.array z wartościami znalezionych współczynników $a_0, a_1, a_2...$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1d469861e0212560502a4558138d3af9",
     "grade": false,
     "grade_id": "cell-343658226c6ad335",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Generowanie danych do następnych zadań\n",
    "tmp_x = np.arange(-1, 1, 0.25)\n",
    "tmp_y = np.polynomial.polynomial.polyval(tmp_x,np.array((-0.1, 0.4, -0.5)))\n",
    "data_polyfit = np.zeros((len(tmp_x), 2))\n",
    "for i in range(len(tmp_x)):\n",
    "    data_polyfit[i][0] = tmp_x[i]\n",
    "    data_polyfit[i][1] = tmp_y[i] + np.random.uniform(-0.1, 0.1)\n",
    "answer_polyfit=np.polyfit(data_polyfit[:,0],data_polyfit[:,1],2)\n",
    "answer_polyfit=answer_polyfit[::-1]\n",
    "\n",
    "print(answer_polyfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e1c4a354423b390275ec8ddbc21802f5",
     "grade": false,
     "grade_id": "cell-07472a9864c73007",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def SGD_polyfit(data, N, alfa, steps):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = SGD_polyfit(data_polyfit, 2, 0.001, 250000)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e95f964b3440eb6d211ba864717ee8d3",
     "grade": true,
     "grade_id": "cell-0e8df4057fae5929",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(int(round(100*out[0])), int(round(100*answer_polyfit[0])))\n",
    "np.testing.assert_almost_equal(int(round(100*out[1])), int(round(100*answer_polyfit[1])))\n",
    "np.testing.assert_almost_equal(int(round(100*out[2])), int(round(100*answer_polyfit[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a53665f180ecab8195ad712b3f0769ff",
     "grade": false,
     "grade_id": "cell-68031eb8caa53fa8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### W poniższych komórkach można zobaczyć efekt fitowania wielomianu stopnia 10 do 8 punktów danych oraz porównać wynik z prawidłowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = SGD_polyfit(data_polyfit, 10, 0.0005, 200000)\n",
    "print(pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "841255202d5922f47964033ced2642ab",
     "grade": false,
     "grade_id": "cell-c8012eb74cdce02a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "iksy = np.arange(-4, 4, 0.02)\n",
    "igreki = np.polynomial.polynomial.polyval(iksy, pol)\n",
    "\n",
    "plt.axis([-1.5, 1.5, -1.5, 0.5])\n",
    "plt.plot(data_polyfit[:,0],data_polyfit[:,1],'o', color='red', label='data')\n",
    "plt.plot(iksy, np.polynomial.polynomial.polyval(iksy, answer_polyfit), '--', color='gray', label='correct')\n",
    "plt.plot(iksy, igreki, '-', color='blue', label='fit')\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "39dfc6f068ce2a0e2b665a7b6621545d",
     "grade": false,
     "grade_id": "cell-33035e3279e9e9a2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Regularyzacja L2\n",
    "\n",
    "Jak widać w poprzednim zadaniu, próba dopasowania wielomianu o zbyt dużym stopniu do zbyt małej ilości danych prowadzi do przefitowania. Przefitowanie jest częstym problemem w zastosowaniach uczenia maszynowego. Najprostszym rozwiązaniem jest zwiększenie ilości danych, co jednak nie zawsze jest możliwe (a czasami nawet to nie pomaga). Inną metodą jest regularyzacja L2. Polega ona na dodaniu dodatkowego członu do funkcji błędu, który wymusza stosowanie małych wartości parametrów.\n",
    "\n",
    "$$L(\\overline{a})=\\sum_{i=0}^{n-1} (y_i-p(x_i))^2 + \\eta \\sum_{j=0}^{N} a_{j}^2 $$\n",
    "\n",
    "gdzie $N$ to stopień wielomianu.\n",
    "\n",
    "Zmieniony gradient L ze względu na $a_j$ jest równy:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial a_j}=-2\\sum_{i=0}^{n-1}(y_i-p(x_i))x_i^j+ \\eta a_j$$\n",
    "\n",
    "Na początek można wziąć $\\eta=10^{-4}$ i stopniowo zwiększać. Zauważ, że dla $\\eta=0$ program powinien zwracać dokładnie te same wyniki co w poprzednim zadaniu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c3a11ef4d21c9b54447279f04182a9ee",
     "grade": false,
     "grade_id": "cell-a5de5893485f1f51",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def SGD_polyfit_L2(data, N, alfa, steps, eta):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_L2 = SGD_polyfit_L2(data_polyfit, 10, 0.0005, 200000, 0.25)\n",
    "print(pol_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0e078f62afb39dce91e4b87653d823c1",
     "grade": false,
     "grade_id": "cell-6801845ed6ba840b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "iksy = np.arange(-2, 2, 0.02)\n",
    "igreki = np.polynomial.polynomial.polyval(iksy, pol)\n",
    "igreki_L2 = np.polynomial.polynomial.polyval(iksy, pol_L2)\n",
    "plt.axis([-1.5, 1.5, -1.5, 0.5])\n",
    "\n",
    "plt.plot(data_polyfit[:,0],data_polyfit[:,1],'o', color='red', label='data')\n",
    "plt.plot(iksy,np.polynomial.polynomial.polyval(iksy,answer_polyfit),'--',color='gray', label='correct')\n",
    "plt.plot(iksy,igreki,'-',color='blue', label='fit')\n",
    "plt.plot(iksy,igreki_L2,'-',color='green', label='fit L2')\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "337b1a28da97a12eee9b6fbd599ea3ba",
     "grade": true,
     "grade_id": "cell-55ae46c2e5a6a0bb",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "out_noL2 = SGD_polyfit_L2(data_polyfit, 8, 0.0005, 200000, 0.0)\n",
    "out_L2 = SGD_polyfit_L2(data_polyfit, 8, 0.0005, 200000, 0.5)\n",
    "np.testing.assert_array_less(np.dot(out_L2, out_L2), np.dot(out_noL2, out_noL2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
